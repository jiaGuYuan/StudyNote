
面试要准备的东西:

验证集怎么生成:
    留出法(hold-out)
    交叉验证法(croaa validation)
    自助法(bootstrap)

算法:
    树模型:
        熵:
            混乱度(信息量)的度量. 熵越大-->越混杂,越无序.
            Entropy = -sum(p*log(p))
            
        ID3:
            使用信息增益作为用于节点分裂的最优特征选择标准.
            信息增益Gain怎么计算?
            信息增益Gain偏向于选择取值较多的特征.
                ---简单理解: 因为特征取值较多时,可以将样本分成更多的簇,这样每个簇中的样本更少更纯,熵值也就更小
        C4.5:
            使用信息增益率作为用于节点分裂的最优特征选择标准.
            信息增益率Gain_ratio怎么计算?
            由于ID3偏向于选择取值较多的特征,C4.5对其进行了优化.
                可以理解为针对特征取值的数目给予一个惩罚.特征取值的数目越大,处罚也就越大.
                使用特征的熵来作为特征取值的数目的惩罚.
        
        CART(Classification and Regression Tree:分类回归树)
            Gini:
                数据不纯度的度量.取值越大数据越不纯.
                怎么计算?
            
            回归树:
                使用MSE作为节点分裂评价标准
                解析式
                连续值的切分
        
        DT:
            树的表示方式:
                图形结构
                规则结构(if-else-...)
                解析式
            
            
        
        有哪些参数?
        Bagging & Boosting:
            Bagging:
                RF
            Boosting:
                AdaBoost:
                    加法模型+指数损失
                    在下一轮迭代调整训练样本的权重,使之前分错的样本权重高,分对的样本权重低.
                    如何调整权重分布?
                        根据带权的样本分布来训练基学习器
                        根据基学习器的分类带权错误率来调整基学习器的权重
                        根据基学习器的分类情况来对样本权重分布进行调整
                        
                Gradient Boosting(GBDT):
                    使用函数的负梯度拟合残差
                XGBoost:
                    
                lightGBM
                
                
            Bagging & Boosting的区别:
                Bagging关注于减少方差,基学习器为强学习器.!!!
                Boosting关注于减少偏差,基学习器为弱学习器.!!!
                
                Bagging在原始集上通过有放回的抽样来构建训练集.
                Boosting方式通过某一种方式改变样本的分布来进行下一次训练.
                
                Bagging的各个子模型的构建是相对独立的,不存在强依赖关系,可进行基于子模型的并行生成.
                Boosting的下一个子模型的构建依赖与当前模型的构建,在模型的构建上是串行的.
                
                Bagging的各个子模型对最终输出的影响是一样的(权重相同).
                Boosting的各个子模型对最终输出的影响是不一样的(会根据分类误差赋予各子模型不同的权重)
                ...
            
        
    
    线性分类模型:
        LR:
            假设函数
            损失函数(对数几率损失)
            优化方法
        
        SVM(核函数有哪些, 软间隔):
            手推
            SVM损失(hinge loss)
            核函数
            软间隔
        
    分类,聚类, 降维..
        PCA:
            PCA & 最小二乘法的区别
        
    聚类算法:
        k-means, k-means++
        如何选取K值:
        如何设置初始值:
        
    NLP基本算法:
        word2vec, fasttext, LDA
    
    推荐相关算法:
        ALS,...

正则化项有什么作用, 一阶正则化项&二阶正则化项的异同:
    正则化项可以通过对参数的限制来防止过拟合.
    L1正则化可以使大量的参数为0,从而产生稀疏解.
    L2正则化可以使参数的取值趋向于0,从而增加模型的泛化能力.
        
有哪些损失函数:
    对数几率损失
    MSE loss
    hinge loss
    0-1损失
    指数损失
        
怎么调参:

怎么判断模型处于何种状态(过/欠拟合), 如何避免模型的过/欠拟合:
        
        
        
模型评估:
    AUC: 横轴: FPR(负样本召回率); 纵轴: TPR(正样本召回率)
        ROC曲线的绘制. 
            --横轴按照负样本数分为(FP+TN)份
              纵轴按照正样本数分为(TP+FN)份,
              将样本按照预测值从大到小排序,每次取出一个样本,如果预测正确则向上走一步,如果预测错误则向右走一步.
              
    

不均衡样本的处理:
    (T/F)(P/N): P/N:预测值; T/F:预测的是否准确
    查准率: 所有预测为真(TP+FP)的结果中,实际为也为真(TP)的比例
        Precision = TP/(TP+FP)  
    召回率: 所有实际为真(TP+FN)的样本中,实际预测为也为真(TP)的比例
        Recall = TP/(TP+FN)
        
    F1评分:
        计算公式?
       
    
负例采样... 

softmax??? & 层次化softmax



大数据:
    spark, mapreduce, hive, hbase
    
缓存:
    redis
        函数:
            client.zadd
            client.zincrby
            client.zrevrange
    
    
编码知识:
    数据结构:
        leetCode刷题, 动态规划(如:背包问题)
        
        
项目准备:
    美化, 贴合职位需求, 项目技术点, 模型参数

    
深度神经网络框架:
    tensorflow 或 pytorch
    
    
    
局部敏感哈希(LSH):
    越相邻的数据越有可能落入同一个桶中.
    mini hashing:
        word-doc矩阵(WN x DM), 按行(word)进行置换, 每次置换后统计各列(doc)的第一个不为0的行号, 得到本次置换的签名向量.
        --> T次置换后,得到(T x DM)的签名矩阵,
        如果两个文档足够相似,那么他们有共现词也就较多,这样他们在经历较少的置换次数时,更可能在(T x DM)的签名矩阵得到相同的列 --> 即产生较大的冲突概率.
        
        
    
延伸:
    为什么方差越大的模型越容易过拟合?
    
    撸: logistics regression(主要是计算SGD)和神经网络(主要是使用动态规划计算BP).
    
    生成模型 & 判别模型:
    
    Lambda架构:
        日志收集: Flume
        分布式存储: Hadoop
        分布式计算: Hadoop,Spark
        视图存储数据库
        nosql(HBase/Cassandra)
        Redis/memcache
        MySQL
        实时数据收集 flume & kafka
        实时数据分析 spark streaming/storm/flink
    
    
业务方面:
    日活有多少
        1w左右
    点击率: 2%
        加入推荐系统后点击率增加到2.5%
        
    指标值 - F1, AUC, 点击率 有多少
        
        
    
    针对具体的业务场景有什么处理
    针对领域文章的推荐有什么优化

    
    
    