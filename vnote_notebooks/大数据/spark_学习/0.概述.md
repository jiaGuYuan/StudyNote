# 高级工具

* Spark SQL: 使用 SQL 处理结构化数据[Spark SQL](http://doc.codingdict.com/7)
* MLlib: 用于机器学习 [MLlib](http://doc.codingdict.com/8)
* GraphX: 用于图计算 [GraphX](http://doc.codingdict.com/9)
* Spark Streaming: 用于准流式计算[Spark Streaming](http://doc.codingdict.com/6)。



## pyspark环境测试

Windows

1. 进入安装位置

   D:\Software\anaconda3\envs\wk_py37\Lib\site-packages\pyspark

2. 在终端中运行测试

   "./bin/spark-submit" examples/src/main/python/pi.py 10

3. 启动pyspark的交互环境

   "./bin/pyspark" --master local[2]

   * `--master`选项可以指定为 [针对分布式集群的 master URL](http://doc.codingdict.com/spark/1/submitting-applications.html#master-urls)

   * `local[N]` 会使用 N 个线程在本地运行

