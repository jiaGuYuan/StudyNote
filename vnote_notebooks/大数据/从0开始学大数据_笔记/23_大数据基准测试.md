# 23_大数据基准测试
大数据基准测试工具HiBench。


**HiBench内置了若干主要的大数据计算程序作为基准测试的负载（workload）**:
* Sort，对数据进行排序大数据程序。
* WordCount，前面多次提到过，词频统计大数据计算程序。
* TeraSort，对1TB数据进行排序，最早是一项关于软件和硬件的计算力的竞赛，所以很多大数据平台和硬件厂商进行产品宣传的时候会用TeraSort成绩作为卖点。
* Bayes分类，机器学习分类算法，用于数据分类和预测。
* k-means聚类，对数据集合规律进行挖掘的算法。
* 逻辑回归，数据进行预测和回归的算法。
* SQL，包括全表扫描、聚合操作（group by）、连接操作（join）几种典型查询SQL。
* PageRank，Web排序算法。

此外还有十几种常用大数据计算程序，支持的大数据框架包括MapReduce、Spark、Storm等。
对于很多非大数据专业人士而言，HiBench的价值不在于对各种大数据系统进行基准测试，而是学习大数据、验证自己大数据平台性能的工具。

对于做大数据平台的工程师，如果等到使用者来抱怨自己维护的大数据平台不稳定、性能差的时候，可能就有点晚了.

**HiBench使用非常简单，只需要三步**：
1. 配置，配置要测试的数据量、大数据运行环境和路径信息等基本参数。
2. 初始化数据，生成准备要计算的数据，比如要测试1TB数据的排序，那么就生成1TB数据。
3. 执行测试，运行对应的大数据计算程序。

如要生成数据，只需要运行bin目录下对应workload的prepare.sh就可以自动生成配置大小的数据。
```
bin/workloads/micro/terasort/prepare/prepare.sh
```

要执行大数据计算，运行run.sh就可以了。
```
bin/workloads/micro/terasort/hadoop/run.sh
bin/workloads/micro/terasort/spark/run.sh
```

有时候我们想要了解一个大数据产品的性能和用法，看了各种资料花了很多时间，最后得到的可能还是一堆不靠谱的N手信息。**但自己跑一个基准测试，也许就几分钟的事，再花点时间看看测试用例，从程序代码到运行脚本，很快就能了解其基本用法，更加省时、高效**。





























